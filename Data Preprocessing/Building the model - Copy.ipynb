{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array1 = np.array([np.nan, 1, 2])\n",
    "\n",
    "# nan_array = np.isnan(array1)\n",
    "# not_nan_array = ~ nan_array\n",
    "# array2 = array1[not_nan_array]\n",
    "\n",
    "# np.count_nonzero(np.isnan(array1))\n",
    "# np.count_nonzero(~np.isnan(array1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gdal\n",
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from skimage import io\n",
    "from PIL import Image\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image6band5</th>\n",
       "      <th>Image6band4</th>\n",
       "      <th>Image6band3</th>\n",
       "      <th>Image6band2</th>\n",
       "      <th>Image6band1</th>\n",
       "      <th>Image5band5</th>\n",
       "      <th>Image5band4</th>\n",
       "      <th>Image5band3</th>\n",
       "      <th>Image5band2</th>\n",
       "      <th>Image5band1</th>\n",
       "      <th>...</th>\n",
       "      <th>Image2band4</th>\n",
       "      <th>Image2band3</th>\n",
       "      <th>Image2band2</th>\n",
       "      <th>Image2band1</th>\n",
       "      <th>Image1band5</th>\n",
       "      <th>Image1band4</th>\n",
       "      <th>Image1band3</th>\n",
       "      <th>Image1band2</th>\n",
       "      <th>Image1band1</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3426.0</td>\n",
       "      <td>869.0</td>\n",
       "      <td>573.5</td>\n",
       "      <td>874.0</td>\n",
       "      <td>979.5</td>\n",
       "      <td>4224.0</td>\n",
       "      <td>939.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>968.0</td>\n",
       "      <td>1103.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1565.5</td>\n",
       "      <td>1520.5</td>\n",
       "      <td>1401.5</td>\n",
       "      <td>1480.5</td>\n",
       "      <td>3063.0</td>\n",
       "      <td>1487.0</td>\n",
       "      <td>973.0</td>\n",
       "      <td>1209</td>\n",
       "      <td>1208.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3304.0</td>\n",
       "      <td>937.5</td>\n",
       "      <td>600.5</td>\n",
       "      <td>888.5</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>4176.0</td>\n",
       "      <td>909.0</td>\n",
       "      <td>579.0</td>\n",
       "      <td>945.0</td>\n",
       "      <td>1088.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>1115.0</td>\n",
       "      <td>1068.0</td>\n",
       "      <td>1247.5</td>\n",
       "      <td>3081.0</td>\n",
       "      <td>1494.0</td>\n",
       "      <td>945.0</td>\n",
       "      <td>1195</td>\n",
       "      <td>1191.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3096.0</td>\n",
       "      <td>891.5</td>\n",
       "      <td>595.5</td>\n",
       "      <td>876.0</td>\n",
       "      <td>990.5</td>\n",
       "      <td>4029.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>574.0</td>\n",
       "      <td>953.0</td>\n",
       "      <td>1107.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1365.5</td>\n",
       "      <td>1292.0</td>\n",
       "      <td>1190.5</td>\n",
       "      <td>1341.5</td>\n",
       "      <td>3443.0</td>\n",
       "      <td>1591.0</td>\n",
       "      <td>974.0</td>\n",
       "      <td>1258</td>\n",
       "      <td>1216.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3634.0</td>\n",
       "      <td>929.5</td>\n",
       "      <td>574.0</td>\n",
       "      <td>917.5</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>3305.0</td>\n",
       "      <td>934.0</td>\n",
       "      <td>588.0</td>\n",
       "      <td>989.0</td>\n",
       "      <td>1095.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1616.0</td>\n",
       "      <td>1618.0</td>\n",
       "      <td>1546.0</td>\n",
       "      <td>1501.0</td>\n",
       "      <td>2838.0</td>\n",
       "      <td>1316.0</td>\n",
       "      <td>874.0</td>\n",
       "      <td>1120</td>\n",
       "      <td>1175.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3329.5</td>\n",
       "      <td>846.5</td>\n",
       "      <td>560.5</td>\n",
       "      <td>866.5</td>\n",
       "      <td>985.0</td>\n",
       "      <td>4186.0</td>\n",
       "      <td>939.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>968.0</td>\n",
       "      <td>1109.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1554.5</td>\n",
       "      <td>1535.0</td>\n",
       "      <td>1425.0</td>\n",
       "      <td>1508.5</td>\n",
       "      <td>3392.0</td>\n",
       "      <td>1614.0</td>\n",
       "      <td>989.0</td>\n",
       "      <td>1243</td>\n",
       "      <td>1197.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>2019.5</td>\n",
       "      <td>1378.0</td>\n",
       "      <td>1242.5</td>\n",
       "      <td>1262.0</td>\n",
       "      <td>1328.0</td>\n",
       "      <td>3460.0</td>\n",
       "      <td>1340.0</td>\n",
       "      <td>673.0</td>\n",
       "      <td>1157.0</td>\n",
       "      <td>1202.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1144.5</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>1105.0</td>\n",
       "      <td>1289.0</td>\n",
       "      <td>2825.0</td>\n",
       "      <td>1560.0</td>\n",
       "      <td>1081.0</td>\n",
       "      <td>1218</td>\n",
       "      <td>1221.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>3102.5</td>\n",
       "      <td>1002.5</td>\n",
       "      <td>691.0</td>\n",
       "      <td>970.5</td>\n",
       "      <td>1079.5</td>\n",
       "      <td>2549.0</td>\n",
       "      <td>1203.5</td>\n",
       "      <td>880.5</td>\n",
       "      <td>1171.0</td>\n",
       "      <td>1262.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1915.5</td>\n",
       "      <td>1900.5</td>\n",
       "      <td>1699.0</td>\n",
       "      <td>1593.0</td>\n",
       "      <td>2650.0</td>\n",
       "      <td>1917.0</td>\n",
       "      <td>1675.0</td>\n",
       "      <td>1574</td>\n",
       "      <td>1559.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>2529.0</td>\n",
       "      <td>1846.5</td>\n",
       "      <td>1792.5</td>\n",
       "      <td>1502.5</td>\n",
       "      <td>1420.5</td>\n",
       "      <td>2352.0</td>\n",
       "      <td>1599.0</td>\n",
       "      <td>1427.0</td>\n",
       "      <td>1375.0</td>\n",
       "      <td>1424.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1893.0</td>\n",
       "      <td>1785.5</td>\n",
       "      <td>1522.5</td>\n",
       "      <td>1482.5</td>\n",
       "      <td>2681.0</td>\n",
       "      <td>2044.0</td>\n",
       "      <td>1840.0</td>\n",
       "      <td>1676</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>2071.0</td>\n",
       "      <td>1186.0</td>\n",
       "      <td>936.5</td>\n",
       "      <td>1025.5</td>\n",
       "      <td>1161.0</td>\n",
       "      <td>2087.0</td>\n",
       "      <td>1192.5</td>\n",
       "      <td>974.5</td>\n",
       "      <td>1090.0</td>\n",
       "      <td>1264.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1443.0</td>\n",
       "      <td>1211.5</td>\n",
       "      <td>1168.0</td>\n",
       "      <td>1322.5</td>\n",
       "      <td>2481.0</td>\n",
       "      <td>1449.0</td>\n",
       "      <td>1180.0</td>\n",
       "      <td>1296</td>\n",
       "      <td>1350.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>2011.5</td>\n",
       "      <td>1218.5</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>1077.5</td>\n",
       "      <td>1150.0</td>\n",
       "      <td>4280.0</td>\n",
       "      <td>1162.5</td>\n",
       "      <td>673.5</td>\n",
       "      <td>1105.0</td>\n",
       "      <td>1195.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1284.5</td>\n",
       "      <td>1211.0</td>\n",
       "      <td>1212.0</td>\n",
       "      <td>1344.0</td>\n",
       "      <td>2736.0</td>\n",
       "      <td>1769.0</td>\n",
       "      <td>1680.0</td>\n",
       "      <td>1527</td>\n",
       "      <td>1506.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Image6band5  Image6band4  Image6band3  Image6band2  Image6band1  \\\n",
       "0         3426.0        869.0        573.5        874.0        979.5   \n",
       "1         3304.0        937.5        600.5        888.5       1003.0   \n",
       "2         3096.0        891.5        595.5        876.0        990.5   \n",
       "3         3634.0        929.5        574.0        917.5       1007.0   \n",
       "4         3329.5        846.5        560.5        866.5        985.0   \n",
       "..           ...          ...          ...          ...          ...   \n",
       "156       2019.5       1378.0       1242.5       1262.0       1328.0   \n",
       "157       3102.5       1002.5        691.0        970.5       1079.5   \n",
       "158       2529.0       1846.5       1792.5       1502.5       1420.5   \n",
       "159       2071.0       1186.0        936.5       1025.5       1161.0   \n",
       "160       2011.5       1218.5       1024.0       1077.5       1150.0   \n",
       "\n",
       "     Image5band5  Image5band4  Image5band3  Image5band2  Image5band1  ...  \\\n",
       "0         4224.0        939.0        580.0        968.0       1103.0  ...   \n",
       "1         4176.0        909.0        579.0        945.0       1088.0  ...   \n",
       "2         4029.0        918.0        574.0        953.0       1107.0  ...   \n",
       "3         3305.0        934.0        588.0        989.0       1095.0  ...   \n",
       "4         4186.0        939.0        580.0        968.0       1109.0  ...   \n",
       "..           ...          ...          ...          ...          ...  ...   \n",
       "156       3460.0       1340.0        673.0       1157.0       1202.0  ...   \n",
       "157       2549.0       1203.5        880.5       1171.0       1262.5  ...   \n",
       "158       2352.0       1599.0       1427.0       1375.0       1424.0  ...   \n",
       "159       2087.0       1192.5        974.5       1090.0       1264.5  ...   \n",
       "160       4280.0       1162.5        673.5       1105.0       1195.5  ...   \n",
       "\n",
       "     Image2band4  Image2band3  Image2band2  Image2band1  Image1band5  \\\n",
       "0         1565.5       1520.5       1401.5       1480.5       3063.0   \n",
       "1         1203.0       1115.0       1068.0       1247.5       3081.0   \n",
       "2         1365.5       1292.0       1190.5       1341.5       3443.0   \n",
       "3         1616.0       1618.0       1546.0       1501.0       2838.0   \n",
       "4         1554.5       1535.0       1425.0       1508.5       3392.0   \n",
       "..           ...          ...          ...          ...          ...   \n",
       "156       1144.5       1125.0       1105.0       1289.0       2825.0   \n",
       "157       1915.5       1900.5       1699.0       1593.0       2650.0   \n",
       "158       1893.0       1785.5       1522.5       1482.5       2681.0   \n",
       "159       1443.0       1211.5       1168.0       1322.5       2481.0   \n",
       "160       1284.5       1211.0       1212.0       1344.0       2736.0   \n",
       "\n",
       "     Image1band4  Image1band3  Image1band2  Image1band1  class  \n",
       "0         1487.0        973.0         1209       1208.0      1  \n",
       "1         1494.0        945.0         1195       1191.0      1  \n",
       "2         1591.0        974.0         1258       1216.0      1  \n",
       "3         1316.0        874.0         1120       1175.0      1  \n",
       "4         1614.0        989.0         1243       1197.0      1  \n",
       "..           ...          ...          ...          ...    ...  \n",
       "156       1560.0       1081.0         1218       1221.0      2  \n",
       "157       1917.0       1675.0         1574       1559.0      2  \n",
       "158       2044.0       1840.0         1676       1575.0      2  \n",
       "159       1449.0       1180.0         1296       1350.0      2  \n",
       "160       1769.0       1680.0         1527       1506.0      2  \n",
       "\n",
       "[161 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading the training data\n",
    "\n",
    "data = pd.read_csv(\"C:\\\\Users\\\\Lenovo\\\\Desktop\\\\Harvesting_Unsupervised\\\\train.csv\")\n",
    "data.drop(data.columns[0], axis = 1, inplace = True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.4260e+03, 8.6900e+02, 5.7350e+02, ..., 1.2090e+03, 1.2080e+03,\n",
       "        1.0000e+00],\n",
       "       [3.3040e+03, 9.3750e+02, 6.0050e+02, ..., 1.1950e+03, 1.1910e+03,\n",
       "        1.0000e+00],\n",
       "       [3.0960e+03, 8.9150e+02, 5.9550e+02, ..., 1.2580e+03, 1.2160e+03,\n",
       "        1.0000e+00],\n",
       "       ...,\n",
       "       [2.5290e+03, 1.8465e+03, 1.7925e+03, ..., 1.6760e+03, 1.5750e+03,\n",
       "        2.0000e+00],\n",
       "       [2.0710e+03, 1.1860e+03, 9.3650e+02, ..., 1.2960e+03, 1.3500e+03,\n",
       "        2.0000e+00],\n",
       "       [2.0115e+03, 1.2185e+03, 1.0240e+03, ..., 1.5270e+03, 1.5060e+03,\n",
       "        2.0000e+00]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = data.to_numpy()\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some useful commands for numpy array\n",
    "\n",
    "# np.max(train)\n",
    "\n",
    "# np.where(train == np.max(train))\n",
    "# train[40, 16]\n",
    "\n",
    "# np.count_nonzero(np.isnan(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(161, 31)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# splitting the train data in train and cross validation in 80-20 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # creating matrix\n",
    "# input_matrix = np.arange(46928*28*28).reshape((46928,28,28))\n",
    "# print('Input shape: ', input_matrix.shape)\n",
    "# # splitting into two matrices of second matrix by size\n",
    "# second_size = 5000/46928\n",
    "\n",
    "# X1, X2 = train_test_split(input_matrix, test_size=second_size)\n",
    "\n",
    "# print('X1 shape: ', X1.shape)\n",
    "# print('X2 shape: ', X2.shape)\n",
    "\n",
    "# output:::\n",
    "            \n",
    "# Input shape:  (46928, 28, 28)\n",
    "# X1 shape:  (41928, 28, 28)\n",
    "# X2 shape:  (5000, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_size = 20/80\n",
    "\n",
    "train_1, cv = train_test_split(train, test_size = cv_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120, 30), (120, 1), (41, 30), (41, 1))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = train_1[:, :30]\n",
    "train_y = train_1[:, 30:]\n",
    "\n",
    "cv_x = cv[:, :30]\n",
    "cv_y = cv[:, 30:]\n",
    "\n",
    "train_x.shape, train_y.shape, cv_x.shape, cv_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_y.astype(\"int\")\n",
    "cv_y = cv_y.astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120, 30), (120, 1), (41, 30), (41, 1))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, train_y.shape, cv_x.shape, cv_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30, 120), (1, 120), (30, 41), (1, 41))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = train_x.T\n",
    "train_y = train_y.T\n",
    "\n",
    "cv_x = cv_x.T\n",
    "cv_y = cv_y.T\n",
    "\n",
    "train_x.shape, train_y.shape, cv_x.shape, cv_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for logistic Regression we have output as 0 and 1, but we have 1 and 2, so replacing 1 with 0 and 2 with 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_y[cv_y[:] == 1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_y[cv_y[:] == 2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y[train_y[:] == 1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y[train_y[:] == 2] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preparing the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the test data\n",
    "# for refer tp separate fiel\n",
    "# in this file read all the images, split the images individual image in single band image, convert them into numpu array\n",
    "# create a dataframe reading all the pixels values expect those of the training(161) and concat them\n",
    "# for the test dataframe will have (5 x ((8963*8298)-161))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking a sample of the testdata and seeing that does it perform, accordingly\n",
    "# testing on the indices (3320:4150, 3588:4485) of all images and all bands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the csv file which has the labeled indices..\n",
    "\n",
    "labeled_indices = pd.read_csv(\"C:\\\\Users\\\\Lenovo\\\\Desktop\\\\Harvesting_Unsupervised\\\\labeled_index.csv\")\n",
    "\n",
    "labeled_indices.drop(labeled_indices.columns[0], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = [\"C:\\\\Users\\\\Lenovo\\\\Desktop\\\\Harvesting_Unsupervised\\\\1.tif\",\n",
    "      \"C:\\\\Users\\\\Lenovo\\\\Desktop\\\\Harvesting_Unsupervised\\\\2.tif\",\n",
    "      \"C:\\\\Users\\\\Lenovo\\\\Desktop\\\\Harvesting_Unsupervised\\\\3.tif\",\n",
    "      \"C:\\\\Users\\\\Lenovo\\\\Desktop\\\\Harvesting_Unsupervised\\\\4.tif\",\n",
    "      \"C:\\\\Users\\\\Lenovo\\\\Desktop\\\\Harvesting_Unsupervised\\\\5.tif\",\n",
    "      \"C:\\\\Users\\\\Lenovo\\\\Desktop\\\\Harvesting_Unsupervised\\\\6.tif\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12397212, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test = np.zeros((4149*2988, 1))\n",
    "sample_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<osgeo.gdal.Dataset; proxy of <Swig Object of type 'GDALDatasetShadow *' at 0x000002A1C74CA810> >\n",
      "(4149, 2988)\n",
      "(12397212, 1)\n",
      "(4149, 2988)\n",
      "(12397212, 1)\n",
      "(4149, 2988)\n",
      "(12397212, 1)\n",
      "(4149, 2988)\n",
      "(12397212, 1)\n",
      "(4149, 2988)\n",
      "(12397212, 1)\n",
      "<osgeo.gdal.Dataset; proxy of <Swig Object of type 'GDALDatasetShadow *' at 0x000002A1CCF32F60> >\n",
      "(4149, 2988)\n",
      "(12397212, 1)\n",
      "(4149, 2988)\n",
      "(12397212, 1)\n",
      "(4149, 2988)\n",
      "(12397212, 1)\n",
      "(4149, 2988)\n",
      "(12397212, 1)\n",
      "(4149, 2988)\n",
      "(12397212, 1)\n",
      "<osgeo.gdal.Dataset; proxy of <Swig Object of type 'GDALDatasetShadow *' at 0x000002A1C74CA810> >\n",
      "(4149, 2988)\n",
      "(12397212, 1)\n",
      "(4149, 2988)\n",
      "(12397212, 1)\n",
      "(4149, 2988)\n",
      "(12397212, 1)\n",
      "(4149, 2988)\n",
      "(12397212, 1)\n",
      "(4149, 2988)\n",
      "(12397212, 1)\n",
      "<osgeo.gdal.Dataset; proxy of <Swig Object of type 'GDALDatasetShadow *' at 0x000002A1CCF32E70> >\n",
      "(4149, 2988)\n",
      "(12397212, 1)\n",
      "(4149, 2988)\n",
      "(12397212, 1)\n",
      "(4149, 2988)\n",
      "(12397212, 1)\n",
      "(4149, 2988)\n",
      "(12397212, 1)\n",
      "(4149, 2988)\n",
      "(12397212, 1)\n",
      "<osgeo.gdal.Dataset; proxy of <Swig Object of type 'GDALDatasetShadow *' at 0x000002A1C74CA810> >\n",
      "(4149, 2988)\n",
      "(12397212, 1)\n",
      "(4149, 2988)\n",
      "(12397212, 1)\n",
      "(4149, 2988)\n",
      "(12397212, 1)\n",
      "(4149, 2988)\n",
      "(12397212, 1)\n",
      "(4149, 2988)\n",
      "(12397212, 1)\n",
      "<osgeo.gdal.Dataset; proxy of <Swig Object of type 'GDALDatasetShadow *' at 0x000002A1CCF32E70> >\n",
      "(4149, 2988)\n",
      "(12397212, 1)\n",
      "(4149, 2988)\n",
      "(12397212, 1)\n",
      "(4149, 2988)\n",
      "(12397212, 1)\n",
      "(4149, 2988)\n",
      "(12397212, 1)\n",
      "(4149, 2988)\n",
      "(12397212, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   nan,    nan,    nan, ...,    nan,    nan,    0. ],\n",
       "       [   nan,    nan,    nan, ...,    nan,    nan,    0. ],\n",
       "       [   nan,    nan,    nan, ...,    nan,    nan,    0. ],\n",
       "       ...,\n",
       "       [2959. , 1015. ,  661.5, ..., 1256. , 1241. ,    0. ],\n",
       "       [2930.5, 1015. ,  739.5, ..., 1262. , 1245. ,    0. ],\n",
       "       [2658. , 1347. , 1130. , ..., 1271. , 1252. ,    0. ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in img:\n",
    "    image = gdal.Open(i)\n",
    "    print(image)\n",
    "    \n",
    "    image_zero = np.zeros((image.RasterYSize, image.RasterXSize, image.RasterCount))\n",
    "    \n",
    "    for b in range(image_zero.shape[2]):\n",
    "        image_zero[:, :, b] = image.GetRasterBand(b + 1).ReadAsArray()\n",
    "        \n",
    "        for a in range(len(labeled_indices[\"x_index\"].values)):\n",
    "            image_zero[:,:,b].T[labeled_indices.iloc[a,0], labeled_indices.iloc[a,1]] = 0\n",
    "            \n",
    "        sample = image_zero[:,:,b].T[0:4149, 0:2988]\n",
    "        print(sample.shape)\n",
    "        sample = sample.reshape((4149*2988, 1))\n",
    "        print(sample.shape)\n",
    "        \n",
    "        sample_test = np.concatenate((sample, sample_test), axis = 1)\n",
    "        \n",
    "sample_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12397212, 31)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test_df = pd.DataFrame(data = sample_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test_df.drop(sample_test_df.columns[30], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = sample_test_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   nan,    nan,    nan, ..., 2959. , 2930.5, 2658. ],\n",
       "       [   nan,    nan,    nan, ..., 1015. , 1015. , 1347. ],\n",
       "       [   nan,    nan,    nan, ...,  661.5,  739.5, 1130. ],\n",
       "       ...,\n",
       "       [   nan,    nan,    nan, ...,  950. ,  989. , 1068. ],\n",
       "       [   nan,    nan,    nan, ..., 1256. , 1262. , 1271. ],\n",
       "       [   nan,    nan,    nan, ..., 1241. , 1245. , 1252. ]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x = test.to_numpy()\n",
    "test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 12397212)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature normaliztion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 120)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(train_x.shape[0]):\n",
    "    a = np.mean(train_x[i, :])\n",
    "    b = np.std(train_x[i, :])\n",
    "    #print(train_x[i, :])\n",
    "    #print(a,\" : \", b ,\"\\n\")\n",
    "    train_x[i, :] = (train_x[i, :] - a) / b\n",
    "    cv_x[i, :] = (cv_x[i, :] - a) / b\n",
    "    test_x[i, :] = (test_x[i, :] - a) / b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: sigmoid\n",
    "\n",
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Compute the sigmoid of z\n",
    "\n",
    "    Arguments:\n",
    "    z -- A scalar or numpy array of any size.\n",
    "\n",
    "    Return:\n",
    "    s -- sigmoid(z)\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ### (≈ 1 line of code)\n",
    "    s = 1/(1 + np.exp(-z))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: initialize_with_zeros\n",
    "\n",
    "def initialize_with_zeros(dim):\n",
    "    \"\"\"\n",
    "    This function creates a vector of zeros of shape (dim, 1) for w and initializes b to 0.\n",
    "    \n",
    "    Argument:\n",
    "    dim -- size of the w vector we want (or number of parameters in this case)\n",
    "    \n",
    "    Returns:\n",
    "    w -- initialized vector of shape (dim, 1)\n",
    "    b -- initialized scalar (corresponds to the bias)\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### (≈ 1 line of code)\n",
    "    w = np.zeros((dim, 1))\n",
    "    b = 0\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    assert(w.shape == (dim, 1))\n",
    "    assert(isinstance(b, float) or isinstance(b, int))\n",
    "    \n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: propagate\n",
    "\n",
    "def propagate(w, b, X, Y):\n",
    "    \"\"\"\n",
    "    Implement the cost function and its gradient for the propagation explained above\n",
    "\n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of size (num_px * num_px * 3, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat) of size (1, number of examples)\n",
    "\n",
    "    Return:\n",
    "    cost -- negative log-likelihood cost for logistic regression\n",
    "    dw -- gradient of the loss with respect to w, thus same shape as w\n",
    "    db -- gradient of the loss with respect to b, thus same shape as b\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    \n",
    "    # FORWARD PROPAGATION (FROM X TO COST)\n",
    "    ### START CODE HERE ### (≈ 2 lines of code)\n",
    "    A = sigmoid(np.dot(w.T, X) + b)                                           # compute activation\n",
    "    cost = -1 / m * np.sum(Y * np.log(A) + (1-Y) * np.log(1-A))                                 # compute cost\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # BACKWARD PROPAGATION (TO FIND GRAD)\n",
    "    ### START CODE HERE ### (≈ 2 lines of code)\n",
    "    dw = (1/m)*np.dot(X, (A-Y).T)\n",
    "    db = (1/m)*np.sum((A - Y))\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    assert(dw.shape == w.shape)\n",
    "    assert(db.dtype == float)\n",
    "    cost = np.squeeze(cost)\n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: optimize\n",
    "\n",
    "def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False):\n",
    "    \"\"\"\n",
    "    This function optimizes w and b by running a gradient descent algorithm\n",
    "    \n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of shape (num_px * num_px * 3, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat), of shape (1, number of examples)\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    print_cost -- True to print the loss every 100 steps\n",
    "    \n",
    "    Returns:\n",
    "    params -- dictionary containing the weights w and bias b\n",
    "    grads -- dictionary containing the gradients of the weights and bias with respect to the cost function\n",
    "    costs -- list of all the costs computed during the optimization, this will be used to plot the learning curve.\n",
    "    \n",
    "    Tips:\n",
    "    You basically need to write down two steps and iterate through them:\n",
    "        1) Calculate the cost and the gradient for the current parameters. Use propagate().\n",
    "        2) Update the parameters using gradient descent rule for w and b.\n",
    "    \"\"\"\n",
    "    \n",
    "    costs = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        \n",
    "        # Cost and gradient calculation (≈ 1-4 lines of code)\n",
    "        ### START CODE HERE ### \n",
    "        grads, cost = propagate(w, b, X, Y)\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        # Retrieve derivatives from grads\n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        # update rule (≈ 2 lines of code)\n",
    "        ### START CODE HERE ###\n",
    "        w = w - learning_rate*dw\n",
    "        b = b - learning_rate*db\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        # Record the costs\n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "        \n",
    "        # Print the cost every 100 training iterations\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "    \n",
    "    params = {\"w\": w,\n",
    "              \"b\": b}\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return params, grads, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: predict\n",
    "\n",
    "def predict(w, b, X):\n",
    "    '''\n",
    "    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n",
    "    \n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of size (num_px * num_px * 3, number of examples)\n",
    "    \n",
    "    Returns:\n",
    "    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n",
    "    '''\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    Y_prediction = np.zeros((1,m))\n",
    "    w = w.reshape(X.shape[0], 1)\n",
    "    \n",
    "    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n",
    "    ### START CODE HERE ### (≈ 1 line of code)\n",
    "    A = sigmoid(np.dot(w.T, X) + b)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    for i in range(A.shape[1]):\n",
    "        \n",
    "        # Convert probabilities A[0,i] to actual predictions p[0,i]\n",
    "        ### START CODE HERE ### (≈ 4 lines of code)\n",
    "        if A[0, i] > 0.5:\n",
    "            Y_prediction[0, i] = 1\n",
    "        else:\n",
    "            Y_prediction[0, i] = 0\n",
    "        ### END CODE HERE ###\n",
    "    \n",
    "    assert(Y_prediction.shape == (1, m))\n",
    "    \n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: model\n",
    "\n",
    "def model(X_train, Y_train, X_test, Y_test, num_iterations = 2000, learning_rate = 0.5, print_cost = False):\n",
    "    \"\"\"\n",
    "    Builds the logistic regression model by calling the function you've implemented previously\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set represented by a numpy array of shape (num_px * num_px * 3, m_train)\n",
    "    Y_train -- training labels represented by a numpy array (vector) of shape (1, m_train)\n",
    "    X_test -- test set represented by a numpy array of shape (num_px * num_px * 3, m_test)\n",
    "    Y_test -- test labels represented by a numpy array (vector) of shape (1, m_test)\n",
    "    num_iterations -- hyperparameter representing the number of iterations to optimize the parameters\n",
    "    learning_rate -- hyperparameter representing the learning rate used in the update rule of optimize()\n",
    "    print_cost -- Set to true to print the cost every 100 iterations\n",
    "    \n",
    "    Returns:\n",
    "    d -- dictionary containing information about the model.\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # initialize parameters with zeros (≈ 1 line of code)\n",
    "    w, b = initialize_with_zeros(X_train.shape[0])\n",
    "\n",
    "    # Gradient descent (≈ 1 line of code)\n",
    "    parameters, grads, costs = optimize(w, b, X_train, Y_train, num_iterations, learning_rate, print_cost)\n",
    "    \n",
    "    # Retrieve parameters w and b from dictionary \"parameters\"\n",
    "    w = parameters[\"w\"]\n",
    "    b = parameters[\"b\"]\n",
    "    \n",
    "    # Predict test/train set examples (≈ 2 lines of code)\n",
    "    Y_prediction_test = predict(w, b, X_test)\n",
    "    Y_prediction_train = predict(w, b, X_train)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Print train/test Errors\n",
    "    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n",
    "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))\n",
    "\n",
    "    \n",
    "    d = {\"costs\": costs,\n",
    "         \"Y_prediction_test\": Y_prediction_test, \n",
    "         \"Y_prediction_train\" : Y_prediction_train, \n",
    "         \"w\" : w, \n",
    "         \"b\" : b,\n",
    "         \"learning_rate\" : learning_rate,\n",
    "         \"num_iterations\": num_iterations}\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.693147\n",
      "Cost after iteration 100: 0.261008\n",
      "Cost after iteration 200: 0.169562\n",
      "Cost after iteration 300: 0.129147\n",
      "Cost after iteration 400: 0.105819\n",
      "Cost after iteration 500: 0.090388\n",
      "Cost after iteration 600: 0.079303\n",
      "Cost after iteration 700: 0.070890\n",
      "Cost after iteration 800: 0.064249\n",
      "Cost after iteration 900: 0.058852\n",
      "Cost after iteration 1000: 0.054365\n",
      "Cost after iteration 1100: 0.050566\n",
      "Cost after iteration 1200: 0.047303\n",
      "Cost after iteration 1300: 0.044465\n",
      "Cost after iteration 1400: 0.041971\n",
      "Cost after iteration 1500: 0.039760\n",
      "Cost after iteration 1600: 0.037786\n",
      "Cost after iteration 1700: 0.036010\n",
      "Cost after iteration 1800: 0.034404\n",
      "Cost after iteration 1900: 0.032943\n",
      "train accuracy: 100.0 %\n",
      "test accuracy: 100.0 %\n"
     ]
    }
   ],
   "source": [
    "# d = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 2000, learning_rate = 0.005, print_cost = True)\n",
    "\n",
    "a = model(train_x, train_y, cv_x, cv_y, num_iterations = 2000, learning_rate = 0.005, print_cost = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " costs   :::   [0.6931471805599453, 0.26100790308559396, 0.16956170440933485, 0.12914726093324203, 0.10581904037575666, 0.09038752925381151, 0.07930265335504015, 0.07088964997632125, 0.06424914203263996, 0.058851924642643605, 0.05436465325775796, 0.05056597234543956, 0.047302571779323, 0.04446456194978833, 0.04197090088962292, 0.039760371045263865, 0.03778577498752145, 0.03601007792402668, 0.03440377069851706, 0.032943022197904286]\n",
      "\n",
      "\n",
      " Y_prediction_test   :::   [[1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0.\n",
      "  0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0.]]\n",
      "\n",
      "\n",
      " Y_prediction_train   :::   [[1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1.\n",
      "  0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0.\n",
      "  1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1.\n",
      "  1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1.]]\n",
      "\n",
      "\n",
      " w   :::   [[-0.58075074]\n",
      " [ 0.42787618]\n",
      " [ 0.4696828 ]\n",
      " [ 0.41870278]\n",
      " [ 0.44057837]\n",
      " [-0.30936888]\n",
      " [ 0.42235173]\n",
      " [ 0.2234685 ]\n",
      " [ 0.33368277]\n",
      " [ 0.20967666]\n",
      " [ 0.20265647]\n",
      " [ 0.36495369]\n",
      " [ 0.16634548]\n",
      " [ 0.29746472]\n",
      " [ 0.18971884]\n",
      " [ 0.02745256]\n",
      " [ 0.00080934]\n",
      " [ 0.00641328]\n",
      " [ 0.01270745]\n",
      " [ 0.01828147]\n",
      " [-0.27323342]\n",
      " [-0.31580741]\n",
      " [-0.286004  ]\n",
      " [-0.23551024]\n",
      " [-0.16834718]\n",
      " [-0.06510917]\n",
      " [ 0.08720821]\n",
      " [ 0.1616581 ]\n",
      " [ 0.0809042 ]\n",
      " [ 0.09592353]]\n",
      "\n",
      "\n",
      " b   :::   0.4902834500114212\n",
      "\n",
      "\n",
      " learning_rate   :::   0.005\n",
      "\n",
      "\n",
      " num_iterations   :::   2000\n"
     ]
    }
   ],
   "source": [
    "for i in a:\n",
    "    print(\"\\n\\n\", i,\"  :::  \", a[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.66209572,  1.62101111,  1.57992649, ..., -0.08898035,\n",
       "        -0.3080983 , -0.07590798],\n",
       "       [ 0.30926541,  0.30926541,  0.11936375, ...,  0.12189577,\n",
       "         0.12189577,  0.30926541],\n",
       "       [-0.64834214, -0.71326803, -0.71146454, ..., -0.17582593,\n",
       "        -0.28042875, -0.15598746],\n",
       "       ...,\n",
       "       [-0.70178224, -0.74591434, -0.75572148, ..., -0.56448235,\n",
       "        -0.74101078, -0.65274656],\n",
       "       [-0.18096857, -0.26035364, -0.29563589, ..., -0.9748193 ,\n",
       "        -1.11594832, -1.02774269],\n",
       "       [ 0.33204063,  0.44920272,  0.40038518, ..., -0.00968215,\n",
       "         0.01960838,  0.11724346]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(np.isnan(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = predict(a[\"w\"], a[\"b\"], test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 744510)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = test_y.reshape((830,897))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(830, 897)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 1., 1.],\n",
       "       [0., 0., 0., ..., 1., 1., 1.],\n",
       "       [0., 0., 0., ..., 1., 1., 1.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 1., 1.],\n",
       "       [0., 0., 0., ..., 1., 1., 1.],\n",
       "       [0., 0., 0., ..., 1., 1., 1.]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   0., ..., 255., 255., 255.],\n",
       "       [  0.,   0.,   0., ..., 255., 255., 255.],\n",
       "       [  0.,   0.,   0., ..., 255., 255., 255.],\n",
       "       ...,\n",
       "       [  0.,   0.,   0., ..., 255., 255., 255.],\n",
       "       [  0.,   0.,   0., ..., 255., 255., 255.],\n",
       "       [  0.,   0.,   0., ..., 255., 255., 255.]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[x == 1] = 255\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ..., 255, 255, 255],\n",
       "       [  0,   0,   0, ..., 255, 255, 255],\n",
       "       [  0,   0,   0, ..., 255, 255, 255],\n",
       "       ...,\n",
       "       [  0,   0,   0, ..., 255, 255, 255],\n",
       "       [  0,   0,   0, ..., 255, 255, 255],\n",
       "       [  0,   0,   0, ..., 255, 255, 255]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.astype(\"int\")\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "from skimage.io import imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\anaconda3\\envs\\env_1\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: E:\\Internship_Harvesting\\Prediction\\test.jpg is a low contrast image\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "Lossy conversion from int32 to uint8. Range [0, 255]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "io.imsave(\"E:\\\\Internship_Harvesting\\\\Prediction\\\\test.jpg\" ,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
